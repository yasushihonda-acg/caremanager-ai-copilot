# 15_phase5_expert_meeting.md - Phase 5 専門家会議議事録

## 会議概要
*   **日時:** 2025年11月19日
*   **テーマ:** リアルタイム・コパイロット（定期的AI解析）の実現可能性について
*   **参加者:** プロジェクトマネージャー、リードエンジニア、ベテランケアマネジャー（佐藤）、AIアーキテクト

## 1. 要望の確認
> 「録音終了後ではなく、会話中に『これを聞いてないよ』と教えてほしい。5分〜10分おき（調整可能）にAIが判断してサジェストしてほしい。」

## 2. 議論：一括解析 vs リアルタイム解析
*   **As-Is (Phase 4):** 録音停止時に一括解析。
    *   メリット: 文脈が完全。
    *   デメリット: 修正のチャンスが会話終了後になる。アセスメント中に気づけない。
*   **To-Be (Phase 5):** 録音中、一定間隔（例: 1分毎）に解析。
    *   メリット: 会話の軌道修正が可能（「あ、お金のこと聞くの忘れてた」と気づける）。
    *   技術的課題:
        1.  **断片化:** 短い音声だけだと文脈が通じない。
        2.  **上書きリスク:** 「特になし」という発言が、以前入力された重要な情報を消してしまうリスク。

## 3. 解決策：コンテキスト指向型インターバル解析
*   **差分更新ロジック:** AIには「現在の入力状況（JSON）」と「直近の音声」の両方を渡す。
*   **プロンプト指示:** 「既存の情報を前提とし、この音声で**新たに追加・変更された情報のみ**を抽出しなさい。確信がない場合は既存の値を維持しなさい。」

## 4. 決定事項
1.  **ポーリング実装:** `setInterval` を用いて、録音を継続したまま解析リクエストを投げるアーキテクチャを採用。
2.  **UI:** 解析中も録音を止めない。ヘッダー付近に「AI同席中（解析中）」のステータスを表示する。
3.  **頻度:** デモ用に「30秒 / 1分 / 5分」で切り替え可能にする（実際の現場では5-10分が適当だが、デモでは短縮が必要）。

## 5. アクションプラン
*   `geminiService.ts` の解析関数に `currentData` 引数を追加する。
*   `TouchAssessment.tsx` にインターバル録音ロジックを実装する。